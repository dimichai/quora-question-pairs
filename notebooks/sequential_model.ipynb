{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKT0ZAJDDP1U"
   },
   "source": [
    "## Sequential NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0MktKFTDP1W"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout, BatchNormalization, Input, Embedding, Flatten, concatenate, Dense\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTjlqyuPDP1Z"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2u6kicLVDP1c"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_labels = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsZ38-4CDP1f"
   },
   "outputs": [],
   "source": [
    "# Create the questions vocabulary\n",
    "tokenizer = Tokenizer()\n",
    "questions = pd.concat([df_train['question1'], df_train['question2']])\n",
    "tokenizer.fit_on_texts(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPZEvn8yDP1i"
   },
   "outputs": [],
   "source": [
    "# We add one, because we will need to specify the integer for the largest encoded word as an array index, \n",
    "# e.g. words encoded 1 to 21 with array indices 0 to 21 or 22 positions.\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2ZuNcE3DP1k"
   },
   "outputs": [],
   "source": [
    "# Integer Encode\n",
    "q1_int_sequence = tokenizer.texts_to_sequences(df_train['question1'])\n",
    "q2_int_sequence = tokenizer.texts_to_sequences(df_train['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sc11eXkzDP1m"
   },
   "outputs": [],
   "source": [
    "q1_padded = pad_sequences(q1_int_sequence, maxlen=25)\n",
    "q2_padded = pad_sequences(q2_int_sequence, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkL3P-5ADP1o"
   },
   "outputs": [],
   "source": [
    "# Load the Glove Embeddings\n",
    "f = open('glove.6B.100d.txt')\n",
    "embeddings_index = dict()\n",
    "for line in f:\n",
    "    embedding = line.split()\n",
    "    word_key = embedding[0]\n",
    "    word_weights = np.asarray(embedding[1:], dtype='float32')\n",
    "    embeddings_index[word_key] = word_weights\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhFXvnysDP1s"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding = embeddings_index.get(word)\n",
    "    if embedding is not None:\n",
    "        embedding_matrix[i] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edsqEeghDP1v"
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "q1_input = Input(shape=(25,))\n",
    "q1_model = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=25, trainable=False)(q1_input)\n",
    "q1_model = Flatten()(q1_model)\n",
    "\n",
    "q2_input = Input(shape=(25,))\n",
    "q2_model = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=25, trainable=False)(q2_input)\n",
    "q2_model = Flatten()(q2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x22fg3a2DP1z"
   },
   "outputs": [],
   "source": [
    "merged_model = concatenate([q1_model, q2_model])\n",
    "merged_model = Dense(200, activation='relu')(merged_model)\n",
    "merged_model = Dropout(0.1)(merged_model)\n",
    "merged_model = BatchNormalization()(merged_model)\n",
    "\n",
    "merged_model = Dense(1, activation='sigmoid')(merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82ce37y_DP11"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[q1_input,q2_input], outputs=merged_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZLdQaV6DP13"
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_padded, q2_padded), axis=1)\n",
    "y = df_labels['is_duplicate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elM88rQKDP16"
   },
   "outputs": [],
   "source": [
    "history = model.fit([Q1_train, Q2_train], y_train, epochs=15, verbose=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00-6ELl5Lo1r"
   },
   "outputs": [],
   "source": [
    "# Apply on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L49SkOfJNbbS"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONEfAFmsOBkC"
   },
   "outputs": [],
   "source": [
    "test_q1_seq = tokenizer.texts_to_sequences(df_test['question1'])\n",
    "test_q2_seq = tokenizer.texts_to_sequences(df_test['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "toRwk8feOLll"
   },
   "outputs": [],
   "source": [
    "test_q1_padded = pad_sequences(test_q1_seq, maxlen=25)\n",
    "test_q2_padded = pad_sequences(test_q2_seq, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFdUfJLaORQU"
   },
   "outputs": [],
   "source": [
    "predicted = model.predict([test_q1_padded, test_q2_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_tTSGorOqqo"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = df_test['test_id']\n",
    "submission['is_duplicate'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8s256U3Osq4"
   },
   "outputs": [],
   "source": [
    "submission.loc[submission.is_duplicate < 0.5, 'is_duplicate'] = 0                                                                                                                                                             \n",
    "submission.loc[submission.is_duplicate >= 0.5, 'is_duplicate'] = 1\n",
    "submission['is_duplicate'] = submission['is_duplicate'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "MBWDVktGP47t",
    "outputId": "57459efb-fd41-4cce-e24d-3c1b32c90b81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0       15             1\n",
       "1       20             0\n",
       "2       21             0\n",
       "3       23             0\n",
       "4       34             0"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOs7qBFvQ8vN"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('nn_one_dense_layer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFx09vRnRIve"
   },
   "outputs": [],
   "source": [
    "model.save('nn_one_dense_layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQRKW_goSPBR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sequential_model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
