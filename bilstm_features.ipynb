{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fine_tuning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"qKT0ZAJDDP1U","colab_type":"text"},"cell_type":"markdown","source":["# Final Neural Network Architecture\n","\n","The state of that."]},{"metadata":{"id":"ffXJG-cW9DcP","colab_type":"text"},"cell_type":"markdown","source":["## Download missing files"]},{"metadata":{"id":"UnXA6sVQyXxT","colab_type":"code","outputId":"f2371a74-aadb-417c-bbcc-89fbc13cce01","executionInfo":{"status":"ok","timestamp":1545232718229,"user_tz":-60,"elapsed":118289,"user":{"displayName":"Dimitris Michailidis","photoUrl":"https://lh4.googleusercontent.com/-gqfyDKSRdb4/AAAAAAAAAAI/AAAAAAAAAjM/8OOFAsZoU-M/s64/photo.jpg","userId":"12419194121595599642"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"cell_type":"code","source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-12-19 15:16:42--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2018-12-19 15:16:42--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  6.97MB/s    in 89s     \n","\n","2018-12-19 15:18:11 (9.25 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"metadata":{"id":"ket7GHDt9QDx","colab_type":"text"},"cell_type":"markdown","source":["## Import stuff"]},{"metadata":{"id":"C0MktKFTDP1W","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from keras.layers.embeddings import Embedding\n","from keras.layers import Dropout, BatchNormalization, Input, Embedding, Flatten, concatenate, Dense, LSTM, subtract, multiply, Bidirectional, Lambda\n","from keras.preprocessing.text import one_hot, Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, Model, load_model\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.model_selection import train_test_split\n","import keras.backend as keras_backend"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TFds0UKp9YcR","colab_type":"text"},"cell_type":"markdown","source":["## Setup Hyperparameters"]},{"metadata":{"id":"ggxj_PXI9bX4","colab_type":"code","colab":{}},"cell_type":"code","source":["GLOVE_FILE = 'glove.6B.300d.txt'\n","SEQ_LENGTH = 25\n","EMBEDDING_SIZE = 300\n","LSTM_UNITS = 256\n","FEAT_DENSE_OUTPUT = 64\n","FEAT_ACTIVATION = 'relu'\n","MERGED_DENSE_ACTIVATION = 'relu'\n","MERGED_DENSE_OUTPUT = 200\n","DROPOUT_RATE = 0.1\n","LOSS = 'binary_crossentropy'\n","OPTIMIZER = 'adam'\n","CHECKPOINT_FILE = 'final-{epoch:02d}-{val_loss:.2f}-{val_acc:.3f}.h5'\n","SUBMISSION_FILE = 'final.csv'\n","EPOCHS = 25\n","BATCH_SIZE = 256"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0KQ2CKeh9WL3","colab_type":"text"},"cell_type":"markdown","source":["## Setup Train Data"]},{"metadata":{"id":"J3KQiJ3Ut_eA","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train = pd.read_csv('cleaned_train_data.csv')\n","df_train = df_train.astype({'question1': str, 'question2': str})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vHa2ySMyQsgq","colab_type":"code","colab":{}},"cell_type":"code","source":["df_labels = df_train[['id', 'is_duplicate']]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bg2udcsDwA10","colab_type":"code","colab":{}},"cell_type":"code","source":["features = pd.read_csv('final_train_features.csv')\n","features = features.drop(axis=1, columns=['id'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XsZ38-4CDP1f","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create the questions vocabulary\n","tokenizer = Tokenizer()\n","questions = pd.concat([df_train['question1'], df_train['question2']])\n","tokenizer.fit_on_texts(questions)\n","\n","# We add one, because we will need to specify the integer for the largest encoded word as an array index, \n","# e.g. words encoded 1 to 21 with array indices 0 to 21 or 22 positions.\n","vocab_size = len(tokenizer.word_index) + 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X2ZuNcE3DP1k","colab_type":"code","colab":{}},"cell_type":"code","source":["# Integer Encode & pad the questions\n","q1_int_sequence = tokenizer.texts_to_sequences(df_train['question1'])\n","q2_int_sequence = tokenizer.texts_to_sequences(df_train['question2'])\n","\n","q1_padded = pad_sequences(q1_int_sequence, maxlen=SEQ_LENGTH)\n","q2_padded = pad_sequences(q2_int_sequence, maxlen=SEQ_LENGTH)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GkL3P-5ADP1o","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the Glove Embeddings\n","f = open(GLOVE_FILE)\n","\n","embeddings_index = dict()\n","for line in f:\n","    embedding = line.split()\n","    word_key = embedding[0]\n","    word_weights = np.asarray(embedding[1:], dtype='float32')\n","    embeddings_index[word_key] = word_weights\n","f.close()\n","\n","# Create the embedding matrix of the embeddings contained in the dataset\n","embedding_matrix = np.zeros((vocab_size, 300))\n","for word, i in tokenizer.word_index.items():\n","    embedding = embeddings_index.get(word)\n","    if embedding is not None:\n","        embedding_matrix[i] = embedding"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RKWwCS1R_yqr","colab_type":"text"},"cell_type":"markdown","source":["## Create the Neural Network"]},{"metadata":{"id":"edsqEeghDP1v","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initial, siamese layers\n","embedding_layer = Embedding(vocab_size, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=SEQ_LENGTH, trainable=False)\n","lstm_layer = Bidirectional(LSTM(LSTM_UNITS, activation='tanh'))\n","\n","q1_input = Input(shape=(SEQ_LENGTH,))\n","q1_model = embedding_layer(q1_input)\n","q1_model = lstm_layer(q1_model)\n","\n","q2_input = Input(shape=(SEQ_LENGTH,))\n","q2_model = embedding_layer(q2_input)\n","q2_model = lstm_layer(q2_model)\n","\n","# Create Features Layer\n","features_layer = Input(shape=(features.shape[1],), dtype='float32')\n","features_dense = Dense(FEAT_DENSE_OUTPUT, activation=FEAT_ACTIVATION)(features_layer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x22fg3a2DP1z","colab_type":"code","colab":{}},"cell_type":"code","source":["# Concatenate the outputs of the previous layers and create the merged layers.\n","merged_subtract = subtract([q1_model, q2_model])\n","merged_multiply = multiply([q1_model, q2_model])\n","merged_model = concatenate([q1_model, q2_model, merged_subtract, merged_multiply, features_dense])\n","\n","merged_model = Dropout(DROPOUT_RATE)(merged_model)\n","merged_model = BatchNormalization()(merged_model)\n","merged_model = Dense(MERGED_DENSE_OUTPUT, activation=MERGED_DENSE_ACTIVATION)(merged_model)\n","merged_model = Dropout(DROPOUT_RATE)(merged_model)\n","merged_model = BatchNormalization()(merged_model)\n","merged_model = Dense(MERGED_DENSE_OUTPUT, activation=MERGED_DENSE_ACTIVATION)(merged_model)\n","merged_model = Dropout(DROPOUT_RATE)(merged_model)\n","merged_model = BatchNormalization()(merged_model)\n","merged_model = Dense(MERGED_DENSE_OUTPUT, activation=MERGED_DENSE_ACTIVATION)(merged_model)\n","\n","merged_model = Dense(1, activation='sigmoid')(merged_model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"82ce37y_DP11","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compile the model\n","model = Model(inputs=[q1_input,q2_input, features_layer], outputs=merged_model)\n","\n","model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FmvtZEtBA7ed","colab_type":"code","colab":{}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mA_sjqodb0dg","colab_type":"text"},"cell_type":"markdown","source":["## Train the Neural Network"]},{"metadata":{"id":"1Gw-u1LdA-zI","colab_type":"text"},"cell_type":"markdown","source":["### Train-validation split"]},{"metadata":{"id":"xZLdQaV6DP13","colab_type":"code","colab":{}},"cell_type":"code","source":["# Word Sequences split\n","# Note: use same random stae for splitting both sets.\n","rng_state = 42\n","\n","X = np.stack((q1_padded, q2_padded), axis=1)\n","y = df_labels['is_duplicate']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rng_state)\n","Q1_train = X_train[:,0]\n","Q2_train = X_train[:,1]\n","Q1_test = X_test[:,0]\n","Q2_test = X_test[:,1]\n","\n","# Features split\n","feat_train, feat_test, y_train, y_test = train_test_split(features, y, test_size=0.1, random_state=rng_state)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cz4w-K4IBJka","colab_type":"text"},"cell_type":"markdown","source":["### Train"]},{"metadata":{"id":"elM88rQKDP16","colab_type":"code","colab":{}},"cell_type":"code","source":["callbacks = [EarlyStopping(patience=10, restore_best_weights=True), \n","             ModelCheckpoint(CHECKPOINT_FILE, monitor='val_loss', save_best_only=True)]\n","\n","history = model.fit([Q1_train, Q2_train, feat_train], y_train, epochs=EPOCHS, \n","                    batch_size=BATCH_SIZE, callbacks=callbacks, validation_split=0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VtiuW3K4pYCB","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","\n","plt.title('Training Performance')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['Train Accuracy', 'Validation Accuracy'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fxsp3L4lCSdg","colab_type":"text"},"cell_type":"markdown","source":["### Load the best checkpoint and test it\n","The checkpoint saves the best model depending on validation, but the variable still contains the last iteration.\n","\n","We load the best model and then test it on the test data."]},{"metadata":{"id":"XJMso2XOCbFF","colab_type":"code","colab":{}},"cell_type":"code","source":["model = load_model('SPECIFY_CHECKPOINT_NAME.h5')\n","model.evaluate([Q1_test, Q2_test, feat_test], y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"okHBb6pTBcSi","colab_type":"text"},"cell_type":"markdown","source":["## Predict the Kaggle test set"]},{"metadata":{"id":"L49SkOfJNbbS","colab_type":"code","colab":{}},"cell_type":"code","source":["# Read and prepare the test set\n","df_test = pd.read_csv('test_data.csv')\n","\n","# Tokenize, sequence and padd the texts\n","test_q1_seq = tokenizer.texts_to_sequences(df_test['question1'])\n","test_q2_seq = tokenizer.texts_to_sequences(df_test['question2'])\n","\n","test_q1_padded = pad_sequences(test_q1_seq, maxlen=25)\n","test_q2_padded = pad_sequences(test_q2_seq, maxlen=25)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RFEBWLRXTkhp","colab_type":"code","colab":{}},"cell_type":"code","source":["test_features = pd.read_csv('final_test_features.csv',)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"toRwk8feOLll","colab_type":"code","colab":{}},"cell_type":"code","source":["# Predict\n","predicted = model.predict([test_q1_padded, test_q2_padded, test_features_merged])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PSmTx4C_d_H3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Prepare and save the Submission\n","submission = pd.DataFrame()\n","submission['test_id'] = df_test['test_id']\n","submission['is_duplicate'] = predicted"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W_tTSGorOqqo","colab_type":"code","colab":{}},"cell_type":"code","source":["submission.loc[submission.is_duplicate < 0.5, 'is_duplicate'] = 0                                                                                                                                                             \n","submission.loc[submission.is_duplicate >= 0.5, 'is_duplicate'] = 1\n","submission['is_duplicate'] = submission['is_duplicate'].astype(int)\n","\n","submission.to_csv(SUBMISSION_FILE, index=False)"],"execution_count":0,"outputs":[]}]}